How to prevent "Incorrect block count for file" file system errors from occurring? <body> On our 10.7 Lion installation, 3 out of 9 drives are repeatedly suffering from      Incorrect block count for file   errors when running a codediskutil repairVolume/code command.  hr  ul liThe drives are having capacities of 3TB and 4TB./li liThe drives are attached via a SATA bus./li liThere is no relation between drive capacity and these errors occurring./li liA 4TB drive is listing roughly 5000 file and 1500 folder entries./li liOf these 5000 files, 3000 files are more than 64K in size./li li4 Out of 5 of the 3TB drives are not experiencing these "strongIncorrect block count for file/strong" issues./li liThe drives are encapsulated in silicon jackets to reduce vibrations./li liThe faulty drives also have IO issues in application software, resulting in write() errors. /li liEach 3TB drive with 512 byte sectors is partitioned and formatted with commands similar (emreplace disk number and Volume name/em) to these:/li /ul  hr  precodediskutil unmountDisk /dev/disk2 sudo gpt destroy /dev/disk2 sudo gpt -p 1 create -f /dev/disk2 sudo gpt label -i 1 -l E disk2 sudo gpt add -t hfs /dev/disk2 sudo newfs_hfs -b 65536 -c a=1,c=8,e=1 -n e=1024,c=4096,a=4096 -v E /dev/disk2s1 diskutil mountDisk /dev/disk2 cd /Volumes/E sudo rm -fr .{,_.}{fseventsd,Spotlight-V100,Trashes} mkdir .fseventsd touch .fseventsd/no_log .Trashes sudo touch .metadata_never_index .com.apple.timemachine.donotpresent sudo mdutil -dE -i off /Volumes/E sudo tmutil addexclusion /Volumes/E /code/pre  h1Update #1/h1  ul liWhen ( 33% of the data {1.3TB of free space} is moved to a different drive OR 5 drives were unmounted by the system and manually re-mounted), 1 of the drives does no longer have issues, and the other faulty drive does still have write() issues./li /ul  h1Question/h1  What can be done to prevent these "strongIncorrect block count for file/strong" errors from happening in the first place? 