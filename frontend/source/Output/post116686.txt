How do I find which directories are taking up my inode count? <body> I have a problem with my mac frequently having too many files open and programs starting to crash.  Running df -ih on my system reveals that I have used up all the inodes in / (this is after a fresh restart)  Is there an easy way of traversing my system and finding which directories are the culprit? I do have a lot of files, but I want to know which ones I should be focusing on.  A lot of commands I'm finding don't work well on OSX.  Any help will be appreciated.  precodedf -ih Filesystem      Size   Used  Avail Capacity   iused    ifree %iused  Mounted on /dev/disk0s2   591Gi  526Gi   64Gi    90% 138068137 16799595   89%   / devfs          202Ki  202Ki    0Bi   100%       698        0  100%   /dev map -hosts       0Bi    0Bi    0Bi   100%         0        0  100%   /net map auto_home    0Bi    0Bi    0Bi   100%         0        0  100%   /home map -fstab       0Bi    0Bi    0Bi   100%         0        0  100%   /Network/Servers /dev/disk0s4   303Gi  226Gi   77Gi    75%    321408 80319544    0%   /Volumes/BOOTCAMP /code/pre  <answer116687> Well this isn't just about how many file and folders you have but now large directories are. There are some really cool apps for finding out where your space went.   Try: http://www.daisydiskapp.com  If you want to get rid of files that can take up space and won't really affect your files check out this guy: http://www.titanium.free.fr/downloadonyx.php  Additionally something that might help once you have a bit more space, you can force Spotlight to rebuild it's index, you can disable Time Machine's mobile backups and if you are like me you can even prevent the OS from creating a image of your RAM in the event your system looses power. Add a comment if you are interested in these and I will be happy to give more information.  <answer157349> HFS+ does not use i-nodes. New files can be created as long as there is free disk space.  The compatibility layer that emulates the i-node behaviour always reports a percentage of used i-nodes equal to or slightly less than the percentage of used space.  <comment136470> The only file system that needs free inodes from your list is / and it has plenty. Edit in more of the actual crashing problem since `ls` will show you inode allocation for each directory you care to count. <comment136489> Hi - it's not about disk space - but about inodes. I do use daisydisk, but it won't help in this case. <comment136490> It is using 89% on a cold boot, and after a few days being on, will go up to 100%.  W.r.t crashing problem - I had to restart, so I couldn't take a screenshot, but certain programs, sourcetree etc, showed error messages to the effect of too many open files. <comment136491> If disk0s2 is any variant of HFS, you can forget inode and just free up space on the drive. Again - just use `ls` and `du` and make more room to avoid running out of room if you want to rule that out as the cause of your crash.