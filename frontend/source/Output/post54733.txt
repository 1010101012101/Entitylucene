How can I specify a smaller block size for a Ramdisk? <body> I use a ramdisk to speed up a git repository with a lot ( 60k) of small (~200 bytes) files.  Is there a way to create a ramdisk with a smaller block size?  <answer82745> Executive summary: I don't believe this is possible, at least not for volumes formatted as HFS+.  My current understanding is that HFS+ chooses its file system block size (separate from the physical device block size) according to a fixed default allocation block size that cannot be manually overruled.  img src="https://i.stack.imgur.com/g5W2z.png" alt="HFS+ Default Allocation Block Size"  Discussions in other forums spanning from 2002 to 2011 ( CompGroups, MacRumors among others) suggest using newfs_hfs(8), which has a code-b &lt;blocksize&gt;/code option, to manually set the block size when creating a new file system.  I tried using codenewfs_hfs/code  on various kinds of partitions, on both .dmg diskimages and on physical SATA hard drives (through SATA&lt;-USB interface) and with various file systems (HFS+, FAT16, FAT32.)  When I ran codenewfs_hfs/code with different -b sizes (512, 1024, 2048, 4096, 8192,) indeed it reported success in creating the filesystems with the specified block sizes. I could mount &amp; read/write these volumes normally.  But when I examine the test volumes with codediskutil info &lt;diskname&gt;/code (where code&lt;diskname&gt;/code is disk1, disk4, or whatever your disk is), I always see:  precodeTotal Size:               104.9 MB (104857600 Bytes) (exactly 204800 512-Byte-Blocks) Volume Free Space:        102.4 MB (102385664 Bytes) (exactly 199972 512-Byte-Blocks) Device Block Size:        512 Bytes /code/pre  Noting that the end of the codenewfs_hfs(8)/code man page includes this tidbit:  precodeHISTORY The newfs_hfs command appeared in Mac OS X Server 1.0 .  As of Mac OS X 10.6, this utility no longer generates HFS standard file systems. /code/pre  It would appear that OS X 10.8 (and probably 10.7, and perhaps earlier versions) overrides whatever block size codenewfs_hfs/code claims to create, in favor of default sizes imposed by a higher authority. (??)  hr  One article I came across suggested using OS X's software-RAID utility to create a RAID mirror. Software RAID allows one to specify a RAID strongstripe/strong size, but as this is generally geared towards improving throughput for large files rather than tiny ones, I believe the minimum RAID stripe size is 4KB - not useful for your purposes.  <comment62700> How do you specify the ramdisk now? <comment62729> diskutil erasevolume HFS+ "ramdisk" `hdiutil attach -nomount ram://1165430` <comment62731> I would look at hdiutil resize - however does a ramdisk really help in your scenario - test the speed as disk caching might do enough  + what happens when osx or something else crashes don't you lose work and defeat the object of version control? <comment62858> I currently fail to commit the git repository under 10.7 due to a timeout ( 3h) whereas I can finish the exact same operations in 10mins on a standard Ubuntu VirtualBox image running on the very same machine. <comment62859> In this case it does not defeat the versioning system since I want to do some expensive rebaseing and version comparisons. <comment99624> Awesome! Thanks a lot for the detailed insight!