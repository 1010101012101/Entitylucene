Setting maximum number of running processes <body> I've got program that create N processes, where N is input argument given in command line. I tried to increase this value and got  codefork: Resource temporarily unavailable/code.  Even when setting the relevant params I got the same results on the same value of N.   precodekern.maxproc kern.maxprocperuid  /code/pre  Perhaps there's other places I need to refer to make more processes in my station Or maybe I need to apply the configuration change (I thought it's done automatically) ?  Seem like codefork/code returns codeerrno = 23/code which means :   precode#define ENFILE      23      /* Too many open files in system */ /code/pre  I also tried to increase the following values but it didn't help (although I doubt if it's relevant, since my processes are simple and doesn't access any file)   precodemaxflies maxfilesperproc /code/pre  Also, rebooting the machine to make the new configuration effective, won't help in this case, as the params I've modified return to default value.   My program source code :  precodevoid DoWorkInChild() {     sleep(10); }  int main (int argc, char *argv[]) {     pid_t pids[100000];     int i;     int n = atoi(argv[1]);     printf("I'm grandParent %d n = %d \n", getpid(), n);     /* Start children. */     for (i = 0; i &lt; n; ++i) {             if ((pids[i] = fork()) &lt; 0) {                     printf("errno = %x \n", errno);                     perror("fork");                     abort();             } else if (pids[i] == 0) {                     DoWorkInChild();                     exit(0);             } else {                     printf("I'm process %d \n", pids[i]);             }     }      /* Wait for children to exit. */     int status;     pid_t pid;     while (n &gt; 0) {             pid = wait(&amp;status);             printf("Child with PID %ld exited with status 0x%x.\n", (long)pid, status);             --n;               } } /code/pre  <answer250789> Luckily, I've found the following script that should be run prior to xnu benchmark tests.   precode#!/bin/sh  echo Raising process limits echo limit maxproc 1000 2000 &gt;&gt; /etc/launchd.conf  echo Done. /code/pre  Now, it's working but still cannot see any changes in /etc/sysctl... I wonder what configuration did it change eventually ...    <comment311548> How large is the value of `N`? Have you seen the [Mac OS X Hint:  A solution for Mac OS X process limits](http://hints.macworld.com/article.php?story=200311151254441)? Are you the developer of the program creating the processes? <comment311549> @GrahamMiln, I've tried to Use N=500, while i got ~320 processes already running. when setting maxprocperuid=1024 and maxproc=2048, it should work as i'm the only active user. I also set the file /etc/sysctl.conf but it didn't help (although after reboot the configuration remains). <comment311551> Good to see you found a solution. If you find your processes are causing thrashing, consider using [Grand Central Dispatch](https://developer.apple.com/library/ios/documentation/Performance/Reference/GCD_libdispatch_Ref/index.html#//apple_ref/doc/uid/TP40008079-CH2-SW2) to queue up your tasks. GCD will then run as many as you have available cores – and may even be faster than launching them all at once. <comment311818> `/etc/launchd.conf` has been ignored since 10.10 when launchd was redesigned, so that should not work unless you are on 10.9 or earlier.