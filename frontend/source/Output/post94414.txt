Possible to chain mac minis together? <body> Is there a guide to extending a mac mini by adding several mac minis together to add cpu and memory capacity?  <answer94497> What exactly is your use case? There is not any way to connect two Mac Minis together and have them function as a single machine. But there are ways to split the workload between two different Macs.  Some programs may let you designate master and slave computers, which would allow you to have one computer control the actions of another. Isadora, a video/performance application, is one example.  If you're looking for a more general use case, there are multiple options for automating actions on a Mac. For example, if you wanted to offload converting video files via handbrake, you could have Hazel watching a folder on the second Mini. When you put a video file there, Hazel could automatically run handbrakecli with predefined settings.  Here's an example rule:  img src="https://i.stack.imgur.com/30xEg.jpg" alt="Hazel Rule showing script"  Here Hazel is watching the folder "pinboard-backups"supstrong1/strong/sup. When it sees a file that is a movie it runs a script executing handblakecli (I've set it up so that the converted file ends up back on the first Mini. You could have Hazel running there as well set up to rename the file).  img src="https://i.stack.imgur.com/rgGLJ.jpg" alt="Hazel Rule Showing Trash"  After it runs the script, it moves the file to the trash.  This is just one option; there's plenty of other methods out there. I'd be happy to help point you in a more specific direction if you let me know what you'd like to do.  1: Probably not where you'd be keeping them, but the folder I was editing at the moment.  <answer94502> I understand what you are asking, that is what is called a CCNUMA -- or Cache-Coherent Non-Uniform Memory Architecture.  The easiest thing to do computationally intensive tasks across multiple computers, whether Mac, GNU/Linux, UNIX, or Windoze, is to use MPI or Hadoop.  MPI can, and is difficult to install and use without being a programmer.  Hadoop on the other hand can be relatively straight forward and is in fact used by Big Data, and CERN to mine, collect, and share data.  Hadoop uses Map/Reduce, which is fairly simple to understand, and thus to work with, implementation however, is not the most pleasant.  <comment110799> Take a look at Xgrid. It's a native Mac utility to do distributed computing. I've no experience with it, so not sure if it's easy to setup. <comment110816> Just a note that Xgrid has been discontinued as of ML. You can look to Pooch as its successor: http://forums.macrumors.com/showthread.php?t=1508279 <comment110817> Here is a link to Pooch: http://daugerresearch.com/pooch/download.shtml