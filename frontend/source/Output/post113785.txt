How many files in a folder is too many? <body> Many years ago I vaguely recall that the Finder in Mac OS X would start having problems if a folder contained 2,000 - 3,000 items or more.  Apple doc says that the HFS Plus file system has a theoretical limit of a 2 billion files per folder all Mac OS X versions.  What is the practical limit?  Will having 10,000 photos in a folder be a problem?  <answer113792> Apple has a support document related to that:     Maximum number of files (or files and folders) in a folder (all Mac OS X versions)      Up to 2.1 billion (2)   <answer113821> You can easily try this yourself by running the following in Terminal  precodemkdir ~/t cd ~/t dd if=/dev/random of=test bs=1024 count=16 for i in {1..10000}; do cp test test.$i; done /code/pre  to create a folder containing 10'000 files with 16kB each (replace the 16 in the third line with another number for differently sized files).  <answer274076> Seems that around 10,000 is safe.  However, I've found that if you go a lot higher like 50,000 Finder will never even list the files in the directory when you try to browse it.  I suspect this is why a lot of data recovery software will create a new folder every 10,000 files if you're doing file carving in RAW.  <answer286522> Answering considering a practical example: I have now 326.000 files in a folder, created by an application that download bits from a server. The files are zipped XML files, and my application extracts XML data from it and store it on a local database.   The application runs from the command line. Everything works fine without any issue strongbut/strong coderm */code or codels */code does not work due to the expansion of the wildcard (error message codeArgument list too long/code). Since the files are stored in a temporary folder I can just remove the folder after processing the files.  I didn't try to open the folder with Finder, though. I suspect that could be very slow if possible at all.  <comment133488> Yes, indeed, I did include that link and fact in my question (2nd paragraph). I'm asking about practical *real-world* limits. <comment133489> In 10.6 which I still use at work. the 2000-3000 problem still exists. I have not had the opportunity to use this sort of mass of files on later versions. But I suspect if the docs still say the same thing then the same limit may be a problem. I should add that I never ever have the problem of 2000-3000 on the Local drive. But only across a network drive. <comment133544> Nice empirical test. Thanks. <comment344862> Thanks for this, I had a good laugh. Try having 4M files in a single folder and let me know how it goes (hint - you can't view it, can't `ls`, can't `find`, can't delete it and so forth). <comment344864> I don't know exactly where the limit is drawn, but millions of files will definitely put you in a very big problem (good luck deleting such a folder even with `rm -rf`).