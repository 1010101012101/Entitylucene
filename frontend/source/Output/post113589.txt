OSX Bash for loop - issues with spaces in folder names? <body> I'm getting a bit confused on how to handle spaces in path names when returned in a for loop.  Rationale: I'm cleaning up the permissions on folders and files that I copy over from Windows. Most of the files end up with code-rwx------/code or code-rwxr-xr-x/code permissions so I like to do "codechmod -x */code" and then "codechmod u+x &lt;folders&gt;/code" so I'm trying the following:  precode$ alias getdirs='find . -maxdepth 1 -mindepth 1 -type d | cut -c 3-' $ for i in $(getdirs); do chmod u+x $i; done /code/pre  which works fine, as long as the directories don't have a space in the name.  I've tried different permutations of codechmod u+x "$i"/code, codechmod u+x '$i'/code and similar to get the behavior I wanted, but to no avail.  How to improve my bash code, that works with folder names containing space?  The empurpose/em of this is to be able to remove the "exec" bit from plain files (hence the codechmod -x */code part) but then to restore it to the directories to allow getting into them (codechmod u+x &lt;dirname&gt;/code). From the comments and answers so far I'm thinking that it probably will be easier to do with the proper "find" incantation  <answer113590> Either your alias is only pulling the first bit before the space, or your for loop is only reading the first bit  You can test this by adding some test commentary into your commands, I've limited the alias to only pull the last found directory to isolate the iterations to 1, printed out what the alias thinks it's receiving, and then echoed the variable contents to ensure they match:  precodejaravj$ alias getdirs='find . -maxdepth 1 -mindepth 1 -type d | tail -1|  cut -c 3-' jaravj$ getdirs jaravj$ for i in $(getdirs); do echo "Filename is "$i; chmod u+x $i; done /code/pre  EDIT: changed codedo; echo .../code to codedo echo .../code as it was preventing the line from executing  <answer113594> These kind of things can be tricky in all Unix shells due to the way space is acting as a separator, running aliases as part of shell scripts just makes things even more interesting. I would probably run two passes of find to set first the directories in order, and then next the files:  precodefind . -maxdepth 1 -mindepth 1 -type d -exec chmod u+x '{}' \; find . -maxdepth 1 -mindepth 1 -type f -exec chmod u-x '{}' \; /code/pre  <answer113602> I have two suggestions:  ol liUse codesed/code to put quotes around all the directory names./li liPipe to codexargs/code with argument code-L 1/code. This will execute a command on each line of stdin, obviating the codefor/code loop./li /ol  Try this pipeline:  codefind . -maxdepth 1 -mindepth 1 -type d | cut -c 3- | sed 's/.*/"&amp;"/' | xargs -L 1 chmod u+x/code  <answer113632> In general, the 'proper' way to parse the output of find into a bash loop is to use a codewhile read/code loop, rather than a codefor/code loop. In bash, for loops split using any whitespace (space, tab, newline) by default -- this can be changed, but it's easier and (in my opinion) cleaner to use coderead/code, which reads one line at a time by default.  precodefind . -maxdepth 1 -mindepth 1 -type d | while read i; do chmod u+x "$i"; done /code/pre  Note that I quoted the code"$i"/code there -- that's just as important, because quoting variables prevents the shell from splitting their contents (it's the same problem that codefor/code has, but on the other end). Also note that you can't use single quotes: code'$i'/code would return a literal code$i/code, rather than the contents of the variable.  This will still break on directories with newlines in their names. There is a workaround involving find's code-print0/code, but I've only ever seen newlines in filenames specifically made to test scripts. I don't know if this works with the version of bash in OSX (taken from greg's wiki):  precodefind . -maxdepth 1 -mindepth 1 -type d -print0 | while IFS= read -r -d '' i; do chmod u+x "$i"; done /code/pre  However, in this case it's easier to use globs: a glob ending in a code//code will expand to directories only, so you could just  precodechmod u+x */ /code/pre  (this will work perfectly well with spaces, newlines, anything). More generally, to loop through all directories:  precodefor f in */; do stuff with "$f"; done /code/pre  Unfortunately, there is no way to select files only with globs in any version of bash (this is one of the reasons I prefer zsh, where the globs are powerful enough that you never have to bother with find).  <answer113640> The crux of the issue is that word-splitting happens for command substitution, so that names with spaces in them are indistinguishable from separate names entirely. Globbing does not suffer from this difficulty, so if there's a way to identify directories with a glob and avoid the command substitution entirely, you're home free. And there is:  precodechmod -x * chmod u+x */ /code/pre  But even this is too much work, because codechmod/code has the codeX/code (capital X) symbolic flag, which applies the executable bit only to directories and files that are already executable. So you can really just do:  precodechmod -x * chmod u+X * /code/pre  <comment133286> Why are you using the cut - could you not just use -exec. <comment133287> Each to their own, stringing together a load of commands with pipes can act as a nice way to provide a sort of code based commentary of logical steps, whilst most things can be condensed to minimal steps within commands like `find` and `sed` and `awk` etc, many *less experienced* shell tinkerers find the flowchart style command chains more readable and understandable. <comment133293> Tried your suggestion and the output is as expected: I have a Folder named "ZZPRODUCT data folder" so the output of the FOR is:    Filename is ZZPRODUCT chmod: ZZPRODUCT: No such file or directory Filename is data chmod: data: No such file or directory Filename is folder chmod: folder: No such file or directory <comment133295> @Mark: I want to get rid of the ./ at the beginning of the output to get "nice" output, that's all <comment133296> @stuffe -but then you have to deal with this string problem so I find then both equally complex - My suggestion is give up on shell and use a fuller non text based language - e.g. python, perl, tcl etc. <comment133305> Actually, I'm looking into leveraging find directly to do the change of permissions directly and bypass complex loops and pipes -- will post here if I manage to do it <comment133306> @Mark Actually, that's "plan b". I'm reasonably comfortable with Python (it's my scripting language of choice to develop utilities) and since moving to Mac I've developed some more, but I was trying to do it "the Unix way". From the other answers I believe "the way to go" (other than a full blown Python script) is probably to leverage "find". Will look into it and report back <comment133309> @JJarava the output ISN'T as you expect if your folder is named `ZZPRODUCT data folder`! If it was as expected the output would have been `Filename is ZZPRODUCT data folder` not `Filename is ZZPRODUCT` as you indicate. Stuffe has found the problem. <comment133310> If the output from the echo is truncated, and the output from `getdirs` isn't, the issue is in thap loop, if `getdirs` is truncated, the issue is with your alias.  Having said that, I like @patrix's solution, have you tried it? <comment133333> I would argue that *parsing* the output of `find` is _never_ proper. There is no scenario where parsing the output of `find` is more effective than `-exec` or `-execdir`, or, in very limited circumstances, `find … -print0 | xargs -0 …` <comment133336> Wordsplitting isn't that tricky, and it's actually easier to understand it than to try to avoid it. Besides, at some point you'll inevitably want to write a Python program that uses command-line arguments and those arguments will be subject to word-splitting. <comment133349> @kojiro I disagree. Your comment is overly naive. For repetitive operations on large results lists or find lists gleaned from large file systems that take a long time to search, it's advantageous to store the output of find and process it in separate routines so you don't have to repeat the find command or push the limits of single-line scripting. And that's only one such example where your argument falls apart. There are more. <comment133350> @IanC. So cache the output of `find … -print0`. Also, I contend that caching a list of unsanitized filenames *is* pushing the limits of single-line scripting. The cache-invalidation problem is not insignificant, too. <comment133398> And to answer to the initial need: `find . -maxdepth 1 -mindepth 1 -type f -exec chmod u-x '{}' \;` <comment133409> Thanks for the suggestion about using a while loop - it does indeed work better (i.e., it works). The problem with using glob expansion, is that it won't work with "hidden" directories (such as .Testdir) while FIND will. <comment133430> @JJarava Just do `shopt -s dotglob` to enable dotted-name glob expansion.