Secondary display with VGA connection resolution issue with Macbook Pro under Snow Leopard <body> I am on a MBP Early 2011, running Snow Leopard and am facing a strange issue. If I boot up my system and try to connect to my external display using the MDP-VGA adapter, System Settings won't show the correct resolution for the secondary display. I can see code1440x1050/code and code1600x1200/code, and even if I hit codeDetect Displays/code, nothing will change.  What is my workaround? Connect using MDP-DVI adapter, which will identify the correct resolution of the display (code1680x1050/code), and then fall back to the VGA Adapter to surprisingly see the native resolution of my display listed!!  Do you guys know what is going on here? Thank you in advance.  <answer23105> I had the exact same issue, it's to do with OS X not getting a confirmation from the monitor of it's correct resolution and picking random defaults. Your workaround is pretty much the best way to go, or you can try SwitchResX and try a virtual solution.  <answer48302> Either the VGA cable you are using (or DVI-VGA adaptor, if you're using that) isn't correctly wired for EDID monitor identification, or the monitor itself is sending incorrect EDID information.   Try another VGA cable (or DVI-VGA adaptor, if you're using one) and see if that resolves the problem.  If not, it's likely that your monitor doesn't implement EDID over the VGA connector correctly.  <answer212988> I had this issue with a MBP Retina mid 2012 as I often plug and unplug my laptop from my workstation. The simple solution is to unplug the VGA adaptor from your Mac and the cable and try again. That has worked for me 90% of the time ;)   <comment25779> I took a look at this software and tried it for a few days, but it is a shareware, and I don't feel like paying 14 euros for a thing that such an advanced OS should do. But thanks for the heads up, makes me feel less alone and paranoid. ;) <comment25780> If it helps your work around is better than mine. I ended up using another machine, connecting via VNC and then managing to get the full resolution which was probably one of the worst workarounds in the history of workarounds. <comment25797> The problem is that an "advanced OS" expects digital monitor interfaces, such as DisplayPort, DVI, and HDMI. Older, obsolete OS such as Windows XP are designed around VGA support. Support for VGA is rapidly disappearing throughout the computer and audiovisual industries. <comment25803> Wheat, as soon as you decide to support a technology, it is expected that you do it right, specially when you are paying $50 to get an adaptor. At least you should state that the support for such an old-fashioned technology is not fully implemented. <comment30764> to be honest i would give up on this endeavour and just get a DVI cable to use with the monitor (assuming it's supported). VGA is an outdated analog connection with inferior refresh rate, colour replication and resolution support. It's a shame to be using your awesome macbook with such a legacy connector <comment30765> I understand your position. Unfortunately I use my MBP both at home and at work. One of the displays doesn't have VGA connection so I went for the VGA adapter. But thanks for the tip! <comment30766> which isn't an issue as you can get a DVI adapter ($30 :s) and keep it at the place with the dvi compatible monitor, and use the vga in the place where your stuck with it (which as i understand, isn't the place where your having issues with it) <comment55343> I've seen a lot of DVI-VGA adaptors that don't correctly pass EDID info, so while you don't mention it specifically, it might help others who have this issue and read this question.